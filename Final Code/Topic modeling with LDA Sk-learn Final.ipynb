{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#install packages\n",
    "#!python -m pip install -U nltk\n",
    "#!python -m pip install -U spacy\n",
    "#!python -m spacy download en_core_web_sm\n",
    "#!pip install pyLDAvis==3.2.2\n",
    "\n",
    "# for text preprocessing\n",
    "import re\n",
    "import spacy\n",
    "import pandas as pd\n",
    "\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import string\n",
    "\n",
    "import pyLDAvis.sklearn\n",
    "import os\n",
    "\n",
    "\n",
    "# import vectorizers\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "# import numpy for matrix operation\n",
    "import numpy as np\n",
    "\n",
    "# import LDA from sklearn\n",
    "from sklearn.decomposition import LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'review_id', 'business_id', 'stars', 'text',\n",
       "       'clean_text'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('cleaned_data.csv')\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combining all the documents into a list:\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "corpus =  df['clean_text'].apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert Text into Numerical Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting text into numerical representation\n",
    "n_components = 5\n",
    "n_top_words = 20\n",
    "\n",
    "tf_idf_vectorizer = TfidfVectorizer(tokenizer=lambda doc: doc, lowercase=False)\n",
    "\n",
    "# Converting text into numerical representation. bagofwords\n",
    "cv_vectorizer = CountVectorizer(tokenizer=lambda doc: doc, lowercase=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Array from TF-IDF Vectorizer \n",
    "tf_idf_arr = tf_idf_vectorizer.fit_transform(corpus)\n",
    "\n",
    "# Array from Count Vectorizer \n",
    "cv_arr = cv_vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<351x3345 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 19396 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is our converted text to numerical representation from the Tf-IDF vectorizer\n",
    "tf_idf_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<351x3345 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 19396 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is our converted text to numerical representation from the Count vectorizer\n",
    "cv_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['06',\n",
       " '1',\n",
       " '10',\n",
       " '100',\n",
       " '101',\n",
       " '1010',\n",
       " '1015',\n",
       " '1030',\n",
       " '10min',\n",
       " '10pm',\n",
       " '11',\n",
       " '111215',\n",
       " '12',\n",
       " '120',\n",
       " '127',\n",
       " '13',\n",
       " '130',\n",
       " '14',\n",
       " '145',\n",
       " '15']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating vocabulary array which will represent all the corpus \n",
    "vocab_tf_idf = tf_idf_vectorizer.get_feature_names()\n",
    "\n",
    "# get the vocb list\n",
    "vocab_tf_idf[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['06',\n",
       " '1',\n",
       " '10',\n",
       " '100',\n",
       " '101',\n",
       " '1010',\n",
       " '1015',\n",
       " '1030',\n",
       " '10min',\n",
       " '10pm',\n",
       " '11',\n",
       " '111215',\n",
       " '12',\n",
       " '120',\n",
       " '127',\n",
       " '13',\n",
       " '130',\n",
       " '14',\n",
       " '145',\n",
       " '15']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating vocabulary array which will represent all the corpus \n",
    "vocab_cv = cv_vectorizer.get_feature_names()\n",
    "\n",
    "# get the vocb list\n",
    "vocab_cv[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3345"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "3345"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(len(vocab_tf_idf))\n",
    "display(len(vocab_cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation of LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Implementation of LDA: To implement LDA, pass the corpus: document-term matrix to the model. \n",
    "# We had above obtained the unique words of vocabulary using both TF-IDF and Count Vectorizer. We can continue with either as have the same unique words in both the obtained vocabularies.\n",
    "    \n",
    "# Create object for the LDA class \n",
    "# Inside this class LDA: define the components:\n",
    "lda_model = LatentDirichletAllocation(n_components = 10, max_iter = 20, random_state = 20)\n",
    "\n",
    "# fit transform on model on our count_vectorizer : running this will return our topics \n",
    "X_topics = lda_model.fit_transform(tf_idf_arr)\n",
    "\n",
    "# .components_ gives us our topic distribution \n",
    "topic_words = lda_model.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1 ['wonder' 'pasqual' 'sweet' 'pastri' 'courtesi' 'sampler' 'person' 'top'\n",
      " 'thank' 'werent' 'goto' 'cafe' 'fondu' 'tea']\n",
      "Topic 2 ['wonder' 'world' 'flavorless' 'tip' 'suck' 'lasagn' 'ideal' 'fancier'\n",
      " 'bravissimo' 'antipasti' 'highli' 'stuf' 'sidewalk' 'beauti']\n",
      "Topic 3 ['food' 'good' 'great' 'servic' 'place' 'restaur' 'order' 'pasta'\n",
      " 'italian' 'love' 'tabl' 'one' 'menu' 'nice']\n",
      "Topic 4 ['wonder' 'mood' 'consist' 'potion' 'lasagna' 'voucher' 'tuesday'\n",
      " 'eggplant' 'addit' 'thank' 'owner' 'mom' 'buffet' 'quantiti']\n",
      "Topic 5 ['spectacular' 'salti' 'usual' 'solid' 'lightli' 'sister' 'chill' 'knew'\n",
      " 'fettuccin' 'justifi' 'add' 'alfredo' 'call' 'fix']\n",
      "Topic 6 ['closest' 'itali' 'tea' 'joe' 'ambienc' 'name' 'rodent' 'gather' 'call'\n",
      " 'wouldnt' 'piec' 'graduat' 'five' 'forget']\n",
      "Topic 7 ['wonder' 'appl' 'lasagna' 'beauti' 'addit' 'believ' 'creat' 'pesto'\n",
      " 'whole' 'ownership' 'quickli' 'treasur' 'person' 'old']\n",
      "Topic 8 ['conveni' 'call' 'popular' 'tea' 'ten' 'stuf' 'ad' 'establish' 'yogurt'\n",
      " 'simpl' 'bistro' 'fruit' 'brought' 'met']\n",
      "Topic 9 ['slice' 'tea' 'melt' 'last' 'notch' 'top' 'employe' 'highli' 'prosciutto'\n",
      " 'gf' '45' 'tomato' 'scone' 'ziti']\n",
      "Topic 10 ['last' 'rate' 'waitress' 'housemad' 'beer' 'top' 'brought' 'gluten' 'rat'\n",
      " 'buffet' 'recogn' 'fair' 'month' 'beauti']\n"
     ]
    }
   ],
   "source": [
    "#  Define the number of Words that we want to print in every topic : n_top_words\n",
    "n_top_words = 15\n",
    "\n",
    "for i, topic_dist in enumerate(topic_words):\n",
    "    \n",
    "    # np.argsort to sorting an array or a list or the matrix acc to their values\n",
    "    sorted_topic_dist = np.argsort(topic_dist)\n",
    "    \n",
    "    # Next, to view the actual words present in those indexes we can make the use of the vocab created earlier\n",
    "    topic_words = np.array(vocab_tf_idf)[sorted_topic_dist]\n",
    "    \n",
    "    # so using the sorted_topic_indexes we ar extracting the words from the vocabulary\n",
    "    # obtaining topics + words\n",
    "    # this topic_words variable contains the Topics  as well as the respective words present in those Topics\n",
    "    topic_words = topic_words[:-n_top_words:-1]\n",
    "    print (\"Topic\", str(i+1), topic_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measure Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log Likelihood:  -20335.209594866752\n"
     ]
    }
   ],
   "source": [
    "# Log Likelyhood: Higher the better\n",
    "print(\"Log Likelihood: \", lda_model.score(tf_idf_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity:  8006.357309421285\n",
      "{'batch_size': 128, 'doc_topic_prior': None, 'evaluate_every': -1, 'learning_decay': 0.7, 'learning_method': 'batch', 'learning_offset': 10.0, 'max_doc_update_iter': 100, 'max_iter': 20, 'mean_change_tol': 0.001, 'n_components': 5, 'n_jobs': None, 'perp_tol': 0.1, 'random_state': 20, 'topic_word_prior': None, 'total_samples': 1000000.0, 'verbose': 0}\n"
     ]
    }
   ],
   "source": [
    "# Perplexity: Lower the better. Perplexity = exp(-1. * log-likelihood per word)\n",
    "\n",
    "print(\"Perplexity: \", lda_model.perplexity(tf_idf_arr))\n",
    "\n",
    "print(lda_model.get_params())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find the best topic model and its parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score=nan,\n",
       "             estimator=LatentDirichletAllocation(batch_size=128,\n",
       "                                                 doc_topic_prior=None,\n",
       "                                                 evaluate_every=-1,\n",
       "                                                 learning_decay=0.7,\n",
       "                                                 learning_method='batch',\n",
       "                                                 learning_offset=10.0,\n",
       "                                                 max_doc_update_iter=100,\n",
       "                                                 max_iter=10,\n",
       "                                                 mean_change_tol=0.001,\n",
       "                                                 n_components=10, n_jobs=None,\n",
       "                                                 perp_tol=0.1,\n",
       "                                                 random_state=None,\n",
       "                                                 topic_word_prior=None,\n",
       "                                                 total_samples=1000000.0,\n",
       "                                                 verbose=0),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'learning_decay': [0.5, 0.7, 0.9],\n",
       "                         'n_components': [10, 15, 20, 25, 30]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define Search Param\n",
    "search_params = {'n_components': [10, 15, 20, 25, 30], 'learning_decay': [.5, .7, .9]}\n",
    "\n",
    "# Init the Model\n",
    "lda = LatentDirichletAllocation()\n",
    "\n",
    "# Init Grid Search Class\n",
    "model = GridSearchCV(lda, param_grid=search_params)\n",
    "\n",
    "# Do the Grid Search\n",
    "model.fit(tf_idf_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model's Params:  {'learning_decay': 0.5, 'n_components': 10}\n",
      "Best Log Likelihood Score:  -7167.163540588184\n",
      "Model Perplexity:  25076.317889019807\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Best Model\n",
    "best_lda_model = model.best_estimator_\n",
    "\n",
    "# Model Parameters\n",
    "print(\"Best Model's Params: \", model.best_params_)\n",
    "\n",
    "# Log Likelihood Score\n",
    "print(\"Best Log Likelihood Score: \", model.best_score_)\n",
    "\n",
    "# Perplexity\n",
    "print(\"Model Perplexity: \", best_lda_model.perplexity(tf_idf_arr))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.2.2/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el1711401872785890086439447026\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el1711401872785890086439447026_data = {\"mdsDat\": {\"x\": [32.42095184326172, 0.648955225944519, 71.01968383789062, 3.7859814167022705, -42.666500091552734, -3.6216893196105957, -3.632401704788208, -36.58440017700195, 44.391380310058594, 40.235809326171875], \"y\": [8.115229606628418, 71.70709991455078, 9.971006393432617, 33.18513488769531, -9.22206974029541, -43.52651596069336, -4.171707630157471, 35.804412841796875, 50.61538314819336, -31.591665267944336], \"topics\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"cluster\": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], \"Freq\": [62.24385578396967, 5.51978733905774, 5.276149081252879, 4.775127771336621, 4.127442981537996, 4.01530862207265, 3.871365871041057, 3.7660143140703086, 3.4163151819769144, 2.9886330536841563]}, \"tinfo\": {\"Term\": [\"wonder\", \"last\", \"lasagna\", \"beauti\", \"tea\", \"top\", \"appl\", \"slice\", \"food\", \"pastri\", \"addit\", \"person\", \"call\", \"waitress\", \"whole\", \"brought\", \"tip\", \"usual\", \"thank\", \"old\", \"food\", \"good\", \"great\", \"servic\", \"place\", \"restaur\", \"order\", \"pasta\", \"italian\", \"love\", \"tabl\", \"one\", \"menu\", \"nice\", \"time\", \"delici\", \"go\", \"us\", \"back\", \"drink\", \"appl\", \"creat\", \"treasur\", \"believ\", \"pesto\", \"creme\", \"screw\", \"ownership\", \"lasagna\", \"burle\", \"parpadel\", \"encourag\", \"hi\", \"extens\", \"el\", \"seafood\", \"quickli\", \"addit\", \"thin\", \"carbonara\", \"wonder\", \"whole\", \"beauti\", \"choic\", \"old\", \"person\", \"waitress\", \"plenti\", \"housemad\", \"recogn\", \"rat\", \"rate\", \"gluten\", \"bank\", \"goe\", \"beer\", \"last\", \"georg\", \"fair\", \"rib\", \"piccata\", \"intoler\", \"superior\", \"strand\", \"chanc\", \"french\", \"flat\", \"nightw\", \"voucher\", \"month\", \"waitress\", \"combin\", \"buffet\", \"certainli\", \"begin\", \"brought\", \"top\", \"short\", \"beauti\", \"courtesi\", \"sampler\", \"pasqual\", \"orient\", \"unclear\", \"ninah\", \"lavazza\", \"hello\", \"martini\", \"amazon\", \"strawberri\", \"margarita\", \"superb\", \"everrrr\", \"goto\", \"catch\", \"secret\", \"extraordinari\", \"fondu\", \"cafe\", \"werent\", \"sweet\", \"hungri\", \"pastri\", \"thank\", \"wonder\", \"tip\", \"person\", \"tea\", \"top\", \"romant\", \"potion\", \"mood\", \"tuesday\", \"quantiti\", \"rollitini\", \"bridal\", \"proport\", \"pizzaz\", \"unexcit\", \"occasion\", \"chat\", \"mistak\", \"ubereat\", \"chuco\", \"shower\", \"mom\", \"definet\", \"voucher\", \"femal\", \"valu\", \"discount\", \"consist\", \"eggplant\", \"de\", \"owner\", \"thank\", \"buffet\", \"lasagna\", \"wonder\", \"addit\", \"sister\", \"45\", \"slice\", \"employe\", \"omlett\", \"pepperoni\", \"faux\", \"prosciutto\", \"scone\", \"colin\", \"foo\", \"melt\", \"notch\", \"starchi\", \"unfriendli\", \"strip\", \"trout\", \"gf\", \"mall\", \"basil\", \"brie\", \"ziti\", \"tea\", \"gone\", \"highli\", \"tomato\", \"last\", \"top\", \"sweet\", \"ambienc\", \"wonder\", \"bottl\", \"solid\", \"lightli\", \"fettuccin\", \"spectacular\", \"ahead\", \"allday\", \"chill\", \"parmigiana\", \"otherwis\", \"hummu\", \"shall\", \"church\", \"rome\", \"smaller\", \"foodwa\", \"will\", \"06\", \"mile\", \"surprisingli\", \"salti\", \"justifi\", \"knew\", \"fix\", \"alfredo\", \"add\", \"sister\", \"usual\", \"can\", \"pack\", \"call\", \"ambienc\", \"wonder\", \"conveni\", \"popular\", \"ten\", \"wide\", \"suit\", \"yogurt\", \"establish\", \"gourmet\", \"saffron\", \"road\", \"bistro\", \"thanksgiv\", \"1010\", \"loin\", \"moment\", \"lech\", \"contain\", \"napkin\", \"cleanup\", \"defens\", \"stuf\", \"beat\", \"opent\", \"met\", \"call\", \"soft\", \"fruit\", \"ad\", \"tea\", \"simpl\", \"tomato\", \"gilt\", \"brought\", \"usual\", \"appl\", \"lasagn\", \"suck\", \"world\", \"fancier\", \"ideal\", \"flavorless\", \"antipasti\", \"bravissimo\", \"angel\", \"bennidict\", \"shitti\", \"sometim\", \"vip\", \"forgotten\", \"howi\", \"pet\", \"bravo\", \"altho\", \"sidewalk\", \"tablet\", \"tip\", \"wonder\", \"stuf\", \"coupon\", \"butter\", \"firepit\", \"highli\", \"tomato\", \"romant\", \"beauti\", \"whole\", \"rodent\", \"closest\", \"graduat\", \"gather\", \"coldest\", \"snore\", \"grandma\", \"joy\", \"tear\", \"weep\", \"colleg\", \"joe\", \"midpric\", \"box\", \"snack\", \"salami\", \"footbal\", \"impact\", \"sword\", \"soso\", \"name\", \"mean\", \"forget\", \"itali\", \"ambienc\", \"tea\", \"wouldnt\", \"five\", \"piec\", \"call\"], \"Freq\": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 12.01423051082722, 9.449157657291558, 9.170975337750015, 9.115102880536524, 8.92126147866309, 8.01221867849369, 7.179466214022893, 6.9143512967684595, 6.511398993880243, 6.144253438684224, 6.0628122945578875, 5.898931042294166, 5.811236808961103, 5.7668968505481795, 5.754634196616804, 5.737554961407451, 5.733002293007622, 5.654101315279679, 5.289468363585393, 5.07678476314115, 0.35978653883122164, 0.25095011562207675, 0.22358821892810174, 0.2522259510354419, 0.24148906950704654, 0.2011608896806569, 0.1965081341144812, 0.22921360927445614, 0.3371763020268429, 0.17650775443689962, 0.15540854581701039, 0.1651262667116944, 0.14676083245935823, 0.14399772380873962, 0.1439268942666104, 0.18521381852705343, 0.2255448934818554, 0.27452726443988656, 0.1911735189117723, 0.16183423120980245, 0.4910452282710064, 0.24148363204285844, 0.29353400035562993, 0.19946096597994295, 0.20919850040072552, 0.2155056347479246, 0.19647573896242929, 0.18948201580649326, 0.20039368846917271, 0.16946051811120916, 0.17747379071638372, 0.21124511685551794, 0.1825691209491585, 0.14637197905337515, 0.1475386166027889, 0.191950808548982, 0.2995628263157541, 0.11806082967157189, 0.16936484805999255, 0.14472789816555168, 0.11540573269041898, 0.1147838704089647, 0.1147838704089647, 0.11474593627760421, 0.14006609432270875, 0.15005947145102383, 0.13280299963177059, 0.10770502474851144, 0.15645105371572737, 0.1608865762943599, 0.20614551172117476, 0.13876608846844854, 0.1741116974900653, 0.15464337174311324, 0.1545181744672377, 0.18271708513274704, 0.18798441395831372, 0.1503062462646379, 0.1584542913313499, 0.18412258414934327, 0.1751911577588474, 0.19653287689942267, 0.1575823306589443, 0.1490227348543901, 0.1471440550059807, 0.14100198886474105, 0.15116649270881577, 0.15177054149448785, 0.12533182577781893, 0.13477572976347557, 0.1366792154672686, 0.13312493217934368, 0.12060064367625686, 0.16824467135157212, 0.1280849714536344, 0.1300334343481949, 0.1169871367915584, 0.16782021057451216, 0.1680580032192688, 0.1693305645479842, 0.193191572109542, 0.1499927761639739, 0.1916142725152491, 0.16962153527153884, 0.2370379468067451, 0.16164706650895422, 0.17308188823669, 0.16327780159139132, 0.17290385753678286, 0.15018719374218542, 0.15064455395245765, 0.17305444199144085, 0.1468669137280907, 0.13400416978649443, 0.13137901799603832, 0.12789241290499936, 0.1254777306680735, 0.12453403826017793, 0.12453403826017793, 0.11507649604200153, 0.1074446735548257, 0.11700496244412133, 0.10444166974156344, 0.10396541047245579, 0.10396541047245579, 0.13625608432440361, 0.09940995833587653, 0.14707208832103977, 0.09760600176176165, 0.10460890031810828, 0.10901849577386766, 0.1698289532834366, 0.14622514526947264, 0.12877654819314552, 0.13673576648501606, 0.1454035455085347, 0.13552251771964713, 0.14860010292621975, 0.19149837468260422, 0.14605115109610026, 0.13127565441639832, 0.13300792303766962, 0.24145921590703964, 0.14266656994944196, 0.11526236366632484, 0.11512691053632626, 0.11359105381864656, 0.13560204347615437, 0.12761067751809213, 0.10787482631373245, 0.10683512167732517, 0.15236984463066236, 0.1457320680508841, 0.10760785246044834, 0.09881785953851689, 0.1140303393447974, 0.10746969310448837, 0.13432933141735587, 0.10335633032175882, 0.09754976179326476, 0.11479036477593282, 0.12576007703362438, 0.179568892896561, 0.12505550316311184, 0.13735720973628932, 0.13135185711157288, 0.1505702671228391, 0.14450598989389446, 0.12194363294954678, 0.11614558727749608, 0.1182695234601045, 0.11544446919637256, 0.1330824151639264, 0.13180189238779708, 0.12008426262514439, 0.15147756455967817, 0.11032615537484211, 0.10111357817375531, 0.12895031357472708, 0.09480129545517187, 0.11328891344729924, 0.09311682233811903, 0.09206187435410478, 0.09195313555789084, 0.09195313555789084, 0.10795593679822103, 0.08828598591635663, 0.08663988088445723, 0.08577943398638685, 0.08577943398638685, 0.08577943398638685, 0.14407572935905535, 0.11771559471409643, 0.12119839847809663, 0.11383090590105918, 0.11517061645443892, 0.11723689994947362, 0.1300303065019966, 0.13683979438809005, 0.11323176200494492, 0.10935118389316127, 0.1142074855607337, 0.11272027153856799, 0.1095595966520851, 0.1561414657266297, 0.11721757003502682, 0.11089045877732182, 0.09304268776219825, 0.08864142170552809, 0.10201528082942923, 0.1042592791542691, 0.08475319428387705, 0.08156100396525041, 0.08328974344189218, 0.0979869945100546, 0.07602315120280814, 0.07540401040117199, 0.07540401040117199, 0.07464544558405088, 0.08347221181560399, 0.0769642035593698, 0.0805914348115309, 0.0699120565098123, 0.0699120565098123, 0.10611940714463967, 0.08834546122035955, 0.09451198185979756, 0.09627780853987343, 0.12790607821690422, 0.08644117103439702, 0.09727445622271376, 0.10604239267165659, 0.11497422315253707, 0.1003222490657247, 0.0943921680679083, 0.09190200519884238, 0.09717973891280957, 0.09469207646126451, 0.09025517921439194, 0.1273937873502704, 0.1273937873502704, 0.15417710780582164, 0.10816813218051634, 0.10816813218051634, 0.14468460571380462, 0.0967290242335662, 0.0967290242335662, 0.08074740833851726, 0.0791384943434243, 0.0791384943434243, 0.08541038435043848, 0.07634787131207785, 0.07566915875938114, 0.07418856064973545, 0.07418856064973545, 0.08809323801677184, 0.0738922597970619, 0.09168252235066172, 0.07265449012469212, 0.1279435241510484, 0.17455452736334698, 0.09263719997299381, 0.08702251015658315, 0.09046803550825433, 0.08654508998638366, 0.09448659083231274, 0.09080871717928012, 0.0887066398259417, 0.09089698181546106, 0.08849214821369936, 0.08812222541601807, 0.11484978592212527, 0.08351605610910885, 0.08691402090913998, 0.07719152673589483, 0.07719152673589483, 0.07512042877700954, 0.07512042877700954, 0.07512042877700954, 0.07512042877700954, 0.07860662445518177, 0.09999974309037787, 0.06933978188348737, 0.06858534155685199, 0.07329568427777777, 0.06600957599443434, 0.06440452558776683, 0.06440452558776683, 0.06163513332623153, 0.06163054033047465, 0.09215051071927105, 0.07398976249800174, 0.07861389311904517, 0.1025734073718301, 0.09861836617571249, 0.10158387140790101, 0.08458311853266921, 0.07862075210905811, 0.08391450877673028, 0.085702387594459], \"Total\": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 12.221619145551042, 9.656544745951425, 9.378360383518132, 9.322490362194879, 9.128648855422721, 8.219605916419649, 7.38685537307315, 7.121739570011028, 6.718788354209647, 6.351644190560575, 6.270199438063249, 6.106319975148963, 6.018626844862746, 5.974286551619851, 5.962021687322125, 5.944944571902722, 5.940388747781494, 5.86148855866835, 5.49685680793062, 5.2841712752246774, 0.7006176647293195, 0.503328413623151, 0.4759584648680466, 0.5417893416893046, 0.5228233841326253, 0.4535146981444938, 0.4488926318641296, 0.5288307981375896, 0.8003722895515135, 0.4288675503215644, 0.40778033659228874, 0.4384493980359371, 0.39916302940207765, 0.3963655452489223, 0.39625491475625735, 0.5212145521758802, 0.6363281625817135, 0.7846044467108862, 0.5468527102029276, 0.46927219119998426, 1.5478340595950468, 0.7445864101326941, 0.9466707287035355, 0.6275686331446702, 0.7713459045919968, 0.8494914696526128, 0.7703659697433454, 0.6566509533327619, 0.45359623346392985, 0.42259784691779156, 0.46343668679117855, 0.5628193716186883, 0.5106610834927152, 0.4213873921682555, 0.4309991647513961, 0.5615833226671676, 0.8948660181519784, 0.3712250788765937, 0.5355063493694286, 0.4578890917798089, 0.36865350872380154, 0.3679234231239269, 0.3679234231239269, 0.367902004620566, 0.45287878069313947, 0.49418267837521795, 0.44404401694180645, 0.3608432975106196, 0.533807342910426, 0.5616643887107632, 0.7703659697433454, 0.4752239505697417, 0.6461055468290442, 0.5681532668357457, 0.5779697435466813, 0.8369472710862181, 0.9644327311524462, 0.5927869202867486, 0.9466707287035355, 0.43923087823060214, 0.4303037460147643, 0.5001643596704575, 0.41272961383227735, 0.4041325920121355, 0.4023709001210246, 0.39610734806241793, 0.43503553465314476, 0.4591953082461489, 0.3805144837791385, 0.4120489125835998, 0.4204080711536744, 0.4097859810402847, 0.3757479912418699, 0.5272230846190171, 0.4015635587125972, 0.40861256526030815, 0.37209033569036387, 0.5377969392713139, 0.545185359835278, 0.5800799177366148, 0.7292811705085056, 0.5375090388935347, 0.8562877707675324, 0.7292564415701835, 1.5478340595950468, 0.6833035474308403, 0.8494914696526128, 0.7528100279404399, 0.9644327311524462, 0.5673436817893243, 0.4083642964680859, 0.47161344476097583, 0.40452471213260455, 0.3917735567184743, 0.3890205200394878, 0.3855457692153023, 0.38312777182778185, 0.382187073208769, 0.382187073208769, 0.37274012611301816, 0.36511595886798975, 0.4042516227004781, 0.36215322566851443, 0.3616201567913697, 0.3616201567913697, 0.4804377405834689, 0.3572403982184521, 0.533807342910426, 0.35526980045594075, 0.3874389017391184, 0.4040565827025673, 0.6361065824177193, 0.5752656356474143, 0.4958027229728279, 0.5866894106124163, 0.7292564415701835, 0.6461055468290442, 0.8003722895515135, 1.5478340595950468, 0.7846044467108862, 0.6734892432672408, 0.41358011906126635, 0.7630185906358844, 0.45521855012891055, 0.37332590594128795, 0.3731966061233729, 0.3716571380865524, 0.45395358855937895, 0.4289402036968414, 0.3659622992071676, 0.3649112479912506, 0.5348029971131577, 0.5233808763601214, 0.3869126805046333, 0.35690185462963314, 0.42133588180304965, 0.39774468395725987, 0.5115182512828617, 0.3960825771603032, 0.3777941593755907, 0.4448161625746158, 0.49168966154566873, 0.7528100279404399, 0.4947972185027301, 0.6469771717203484, 0.6267867890564442, 0.8948660181519784, 0.9644327311524462, 0.7292811705085056, 0.6760629843782755, 1.5478340595950468, 0.60302419308358, 0.39184188825326516, 0.3906182385118585, 0.3788416824146309, 0.48605804753390774, 0.3918582204394238, 0.3597887217694279, 0.4669257113991199, 0.3535188428412593, 0.42590171927757825, 0.35183804678692976, 0.3507242438861802, 0.35065650299932893, 0.35065650299932893, 0.4122026092541543, 0.34699462192558744, 0.3453194619600995, 0.3445012707071848, 0.3445012707071848, 0.3445012707071848, 0.5896425838203253, 0.4901322942924549, 0.5122991172579795, 0.4852982070884404, 0.4923351349593813, 0.5585174197091193, 0.6734892432672408, 0.7490197722624294, 0.5267327293591402, 0.5803715083193299, 0.6940390157979268, 0.6760629843782755, 1.5478340595950468, 0.4817345847441326, 0.43075814929746703, 0.4152002288298002, 0.35214628569746537, 0.3487840742268392, 0.40311818019288503, 0.41989733973015747, 0.3438660343582647, 0.3406920596101096, 0.3616951343517698, 0.42722776005844876, 0.3351633491009917, 0.3345491163002515, 0.3345491163002515, 0.33378136505615186, 0.38601681764740575, 0.35628627016745057, 0.3775268165068915, 0.3290346337519244, 0.3290346337519244, 0.49966184325369883, 0.41865206775899266, 0.45551486256718904, 0.47163043269046834, 0.6940390157979268, 0.42121849241311565, 0.5155115263764342, 0.6165407506535215, 0.7528100279404399, 0.6884282961333884, 0.6267867890564442, 0.5884418512131145, 0.8369472710862181, 0.7490197722624294, 0.7006176647293195, 0.38805224321731674, 0.38805224321731674, 0.5165349184492366, 0.3688539833943318, 0.3688539833943318, 0.512077803906787, 0.3573987492171712, 0.3573987492171712, 0.34144344081205547, 0.3398232695983885, 0.3398232695983885, 0.36958897342986285, 0.3370687760979412, 0.3363677602186955, 0.33487530401889243, 0.33487530401889243, 0.3986068778897981, 0.33457408510592396, 0.4178389903521486, 0.33346832760195017, 0.6833035474308403, 1.5478340595950468, 0.49966184325369883, 0.45354720559279244, 0.492971459328531, 0.44931879963966603, 0.6469771717203484, 0.6267867890564442, 0.5673436817893243, 0.9466707287035355, 0.7445864101326941, 0.3507628224185768, 0.4732804520611754, 0.34616134052368147, 0.3675108529593311, 0.33984453174807516, 0.33984453174807516, 0.33776671019100757, 0.33776671019100757, 0.33776671019100757, 0.33776671019100757, 0.3689962115687636, 0.47477505821231303, 0.33198927888475194, 0.33128770505884264, 0.35792631038359296, 0.3288024868806224, 0.3270885437910268, 0.3270885437910268, 0.32429196396333104, 0.32429162512083215, 0.49807155945913606, 0.39598212328943316, 0.449526548515143, 0.6927085086282424, 0.6760629843782755, 0.7528100279404399, 0.5243696467699843, 0.46577340116966687, 0.6298386412793768, 0.6940390157979268], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\"], \"logprob\": [20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -4.764, -5.0042, -5.0341, -5.0402, -5.0617, -5.1691, -5.2789, -5.3165, -5.3766, -5.4346, -5.4479, -5.4753, -5.4903, -5.498, -5.5001, -5.5031, -5.5039, -5.5177, -5.5844, -5.6254, -5.8496, -6.2099, -6.3253, -6.2048, -6.2483, -6.431, -6.4544, -6.3005, -5.9145, -6.5618, -6.6891, -6.6284, -6.7463, -6.7653, -6.7658, -6.5136, -6.3166, -6.1201, -6.482, -6.6486, -5.5386, -6.2483, -6.0532, -6.4395, -6.3919, -6.3622, -6.4546, -6.4909, -6.3897, -6.5574, -6.5112, -6.337, -6.4829, -6.7039, -6.6959, -6.4328, -5.9877, -6.9188, -6.5579, -6.7151, -6.9415, -6.947, -6.947, -6.9473, -6.7479, -6.679, -6.8011, -7.0106, -6.6373, -6.6093, -6.3614, -6.7572, -6.5303, -6.6489, -6.6497, -6.4821, -6.4536, -6.6773, -6.6245, -6.3746, -6.4243, -6.3094, -6.5303, -6.5861, -6.5988, -6.6415, -6.5718, -6.5679, -6.7593, -6.6866, -6.6726, -6.6989, -6.7977, -6.4648, -6.7375, -6.7224, -6.8282, -6.4673, -6.4659, -6.4584, -6.3265, -6.5796, -6.3347, -6.4567, -6.122, -6.5048, -6.4365, -6.4948, -6.4375, -6.5783, -6.4295, -6.2909, -6.4549, -6.5466, -6.5664, -6.5933, -6.6123, -6.6199, -6.6199, -6.6989, -6.7675, -6.6822, -6.7958, -6.8004, -6.8004, -6.5299, -6.8452, -6.4535, -6.8635, -6.7942, -6.7529, -6.3097, -6.4593, -6.5864, -6.5264, -6.4649, -6.5353, -6.4432, -6.1896, -6.4605, -6.5672, -6.5265, -5.9302, -6.4564, -6.6697, -6.6709, -6.6843, -6.5072, -6.5679, -6.7359, -6.7456, -6.3906, -6.4351, -6.7384, -6.8236, -6.6805, -6.7397, -6.5166, -6.7787, -6.8366, -6.6738, -6.5825, -6.2264, -6.5882, -6.4943, -6.539, -6.4025, -6.4436, -6.6134, -6.6621, -6.644, -6.6681, -6.4894, -6.4991, -6.5922, -6.36, -6.677, -6.7642, -6.521, -6.8286, -6.6505, -6.8466, -6.858, -6.8591, -6.8591, -6.6987, -6.8998, -6.9187, -6.9286, -6.9286, -6.9286, -6.4101, -6.6121, -6.583, -6.6457, -6.634, -6.6162, -6.5126, -6.4616, -6.651, -6.6858, -6.6424, -6.6555, -6.6839, -6.3021, -6.5888, -6.6443, -6.8198, -6.8682, -6.7277, -6.7059, -6.9131, -6.9515, -6.9305, -6.768, -7.0218, -7.03, -7.03, -7.0401, -6.9283, -7.0095, -6.9634, -7.1056, -7.1056, -6.6883, -6.8716, -6.8041, -6.7856, -6.5015, -6.8934, -6.7753, -6.689, -6.6081, -6.7444, -6.8054, -6.8321, -6.7763, -6.8022, -6.8502, -6.4081, -6.4081, -6.2173, -6.5717, -6.5717, -6.2808, -6.6835, -6.6835, -6.864, -6.8842, -6.8842, -6.8079, -6.9201, -6.929, -6.9488, -6.9488, -6.777, -6.9528, -6.737, -6.9697, -6.4038, -6.0931, -6.7267, -6.7892, -6.7504, -6.7947, -6.7069, -6.7466, -6.77, -6.7456, -6.7725, -6.6429, -6.378, -6.6966, -6.6567, -6.7753, -6.7753, -6.8025, -6.8025, -6.8025, -6.8025, -6.7572, -6.5165, -6.8826, -6.8935, -6.8271, -6.9318, -6.9564, -6.9564, -7.0004, -7.0005, -6.5982, -6.8177, -6.7571, -6.491, -6.5304, -6.5007, -6.6839, -6.757, -6.6918, -6.6707], \"loglift\": [20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.457, 0.4524, 0.4517, 0.4516, 0.4511, 0.4486, 0.4456, 0.4446, 0.4428, 0.4409, 0.4405, 0.4396, 0.439, 0.4388, 0.4387, 0.4386, 0.4386, 0.4381, 0.4357, 0.4341, 2.2304, 2.2008, 2.1413, 2.1323, 2.1244, 2.0839, 2.0708, 2.0608, 2.0324, 2.009, 1.9322, 1.9203, 1.8963, 1.8843, 1.8841, 1.8622, 1.8596, 1.8467, 1.8458, 1.8322, 1.7488, 1.7708, 1.7259, 1.7506, 1.592, 1.5252, 1.5305, 1.654, 2.1251, 2.0282, 1.9821, 1.962, 1.9134, 1.8846, 1.87, 1.8685, 1.8476, 1.7964, 1.7908, 1.7902, 1.7806, 1.7771, 1.7771, 1.7769, 1.7685, 1.7501, 1.7349, 1.7329, 1.7147, 1.6918, 1.6237, 1.711, 1.6307, 1.6407, 1.6228, 1.4202, 1.3068, 1.5698, 1.1545, 2.1723, 2.1431, 2.1076, 2.0789, 2.0441, 2.0358, 2.0088, 1.9847, 1.9346, 1.9312, 1.9242, 1.9182, 1.9174, 1.9053, 1.8995, 1.8991, 1.8968, 1.8847, 1.8772, 1.8649, 1.8104, 1.7134, 1.7654, 1.5446, 1.5833, 1.1654, 1.6002, 1.4509, 1.5134, 1.3229, 1.7127, 2.1903, 2.185, 2.1743, 2.1147, 2.102, 2.084, 2.0713, 2.0662, 2.0662, 2.0122, 1.9643, 1.9477, 1.9441, 1.941, 1.941, 1.9274, 1.9084, 1.8984, 1.8956, 1.8782, 1.8775, 1.8669, 1.8178, 1.8394, 1.7311, 1.575, 1.6257, 1.5037, 1.0978, 1.5063, 1.5523, 2.0806, 2.0645, 2.0548, 2.0398, 2.039, 2.0297, 2.0068, 2.0027, 1.9935, 1.9867, 1.9595, 1.9365, 1.9354, 1.9309, 1.9081, 1.9065, 1.878, 1.8716, 1.8611, 1.8605, 1.8516, 1.7818, 1.8397, 1.6653, 1.6523, 1.4328, 1.3168, 1.4266, 1.4536, 0.6434, 1.5619, 2.1717, 2.1651, 2.1026, 2.0857, 1.9841, 1.9823, 1.9648, 1.9354, 1.9273, 1.9222, 1.914, 1.913, 1.913, 1.9118, 1.8828, 1.8689, 1.8612, 1.8612, 1.8612, 1.8424, 1.8252, 1.8101, 1.8015, 1.7988, 1.6905, 1.6069, 1.5516, 1.7143, 1.5825, 1.4471, 1.4602, 0.6034, 2.1525, 1.9776, 1.9589, 1.9482, 1.9093, 1.905, 1.886, 1.8786, 1.8495, 1.8107, 1.8067, 1.7956, 1.7892, 1.7892, 1.7814, 1.7478, 1.7468, 1.7349, 1.7302, 1.7302, 1.7298, 1.7234, 1.7065, 1.6902, 1.5879, 1.6955, 1.6115, 1.5189, 1.4, 1.3531, 1.386, 1.4224, 1.126, 1.211, 1.2298, 2.2628, 2.2628, 2.1676, 2.1499, 2.1499, 2.1127, 2.0697, 2.0697, 1.9348, 1.9194, 1.9194, 1.9117, 1.8916, 1.8848, 1.8695, 1.8695, 1.867, 1.8664, 1.8598, 1.8528, 1.7013, 1.1942, 1.6914, 1.7257, 1.6812, 1.7295, 1.4528, 1.4448, 1.521, 1.0334, 1.2467, 2.129, 2.0943, 2.0885, 2.0685, 2.0282, 2.0282, 2.0071, 2.0071, 2.0071, 2.0071, 1.964, 1.9527, 1.9443, 1.9354, 1.9245, 1.9047, 1.8853, 1.8853, 1.8499, 1.8499, 1.823, 1.8329, 1.7667, 1.6003, 1.5853, 1.5074, 1.6859, 1.7313, 1.4947, 1.4187]}, \"token.table\": {\"Topic\": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], \"Freq\": [0.9096107420492058, 1.0092608816501811, 0.946222167976076, 0.9818666297066116, 1.0100349076044508, 0.9320103864038235, 0.9596560200242383, 1.0418545176548328, 0.9446372970508696, 0.9969051337883416, 1.0043040199290703, 0.9825885352255276, 0.9476292206175675, 0.9829059222379232, 0.985907130676157, 0.9732826708904669, 0.9654072732000174, 0.9569073614432417, 1.006370039337266, 1.0236307620402687], \"Term\": [\"back\", \"delici\", \"drink\", \"food\", \"go\", \"good\", \"great\", \"italian\", \"love\", \"menu\", \"nice\", \"one\", \"order\", \"pasta\", \"place\", \"restaur\", \"servic\", \"tabl\", \"time\", \"us\"]}, \"R\": 20, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [3, 7, 10, 1, 4, 9, 5, 8, 2, 6]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el1711401872785890086439447026\", ldavis_el1711401872785890086439447026_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.2.2/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el1711401872785890086439447026\", ldavis_el1711401872785890086439447026_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.2.2/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el1711401872785890086439447026\", ldavis_el1711401872785890086439447026_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=               x          y  topics  cluster       Freq\n",
       "topic                                                  \n",
       "2      32.420952   8.115230       1        1  62.243856\n",
       "6       0.648955  71.707100       2        1   5.519787\n",
       "9      71.019684   9.971006       3        1   5.276149\n",
       "0       3.785981  33.185135       4        1   4.775128\n",
       "3     -42.666500  -9.222070       5        1   4.127443\n",
       "8      -3.621689 -43.526516       6        1   4.015309\n",
       "4      -3.632402  -4.171708       7        1   3.871366\n",
       "7     -36.584400  35.804413       8        1   3.766014\n",
       "1      44.391380  50.615383       9        1   3.416315\n",
       "5      40.235809 -31.591665      10        1   2.988633, topic_info=         Term      Freq     Total Category  logprob  loglift\n",
       "3288   wonder  1.000000  1.000000  Default  20.0000  20.0000\n",
       "1675     last  0.000000  0.000000  Default  19.0000  19.0000\n",
       "1674  lasagna  0.000000  0.000000  Default  18.0000  18.0000\n",
       "375    beauti  0.000000  0.000000  Default  17.0000  17.0000\n",
       "2930      tea  0.000000  0.000000  Default  16.0000  16.0000\n",
       "...       ...       ...       ...      ...      ...      ...\n",
       "2930      tea  0.101584  0.752810  Topic10  -6.5007   1.5074\n",
       "3302  wouldnt  0.084583  0.524370  Topic10  -6.6839   1.6859\n",
       "1176     five  0.078621  0.465773  Topic10  -6.7570   1.7313\n",
       "2218     piec  0.083915  0.629839  Topic10  -6.6918   1.4947\n",
       "533      call  0.085702  0.694039  Topic10  -6.6707   1.4187\n",
       "\n",
       "[320 rows x 6 columns], token_table=      Topic      Freq     Term\n",
       "term                          \n",
       "332       1  0.909611     back\n",
       "863       1  1.009261   delici\n",
       "973       1  0.946222    drink\n",
       "1206      1  0.981867     food\n",
       "1332      1  1.010035       go\n",
       "1338      1  0.932010     good\n",
       "1370      1  0.959656    great\n",
       "1606      1  1.041855  italian\n",
       "1764      1  0.944637     love\n",
       "1848      1  0.996905     menu\n",
       "1972      1  1.004304     nice\n",
       "2051      1  0.982589      one\n",
       "2069      1  0.947629    order\n",
       "2162      1  0.982906    pasta\n",
       "2229      1  0.985907    place\n",
       "2458      1  0.973283  restaur\n",
       "2604      1  0.965407   servic\n",
       "2907      1  0.956907     tabl\n",
       "2996      1  1.006370     time\n",
       "3147      1  1.023631       us, R=20, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[3, 7, 10, 1, 4, 9, 5, 8, 2, 6])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyLDAvis.enable_notebook()\n",
    "panel = pyLDAvis.sklearn.prepare(lda_model, tf_idf_arr, tfidf_vectorizer, mds='tsne',R = 20)\n",
    "panel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding the dominant topic for each doc and labelling docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.02821179 0.02821075 0.8871556  0.02821098 0.02821088]\n",
      " [0.01746981 0.0174713  0.93010308 0.0174697  0.01748611]\n",
      " [0.03081084 0.03081068 0.87675683 0.03081109 0.03081055]\n",
      " ...\n",
      " [0.02003747 0.0200374  0.91985023 0.02003768 0.02003723]\n",
      " [0.01637581 0.01637551 0.93449719 0.0163763  0.01637519]\n",
      " [0.02813372 0.0281336  0.88746529 0.0281339  0.0281335 ]]\n"
     ]
    }
   ],
   "source": [
    "# To view what topics are assigned to the douments:\n",
    "\n",
    "doc_topic = lda_model.transform(tf_idf_arr)  \n",
    "print(doc_topic)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# iterating over every value till the end value\n",
    "for n in range(doc_topic.shape[0]):\n",
    "    \n",
    "    # argmax() gives maximum index value\n",
    "    topic_doc = doc_topic[n].argmax()\n",
    "    \n",
    "    # document is n+1  \n",
    "    #print (\"Document\", n+1, \" -- Topic:\" ,topic_doc)\n",
    "    \n",
    "df['topic'] = topic_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_dict = {0:'Service', 1:'Food',2:'Ambience',\n",
    "             3:'Wait time',4:'Food',5:'Food',6:'Food',7:'Food'}\n",
    "\n",
    "df = df.replace({'topic':topic_dict})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"sklearn_labelled_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
