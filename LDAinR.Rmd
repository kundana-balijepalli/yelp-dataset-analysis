---
title: "On_IR_Statistical_Approaches"
author: "Tamer Abdou, PhD"
date: "20/10/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

#Install and load required packages
```{r}
#https://cran.r-project.org/web/packages/tm/index.html
#install.packages("tm", dependencies = TRUE)
#https://cran.r-project.org/web/packages/RWeka/index.html
#install.packages("RWeka", dependencies = TRUE)
#https://cran.r-project.org/web/packages/textstem/index.html
#install.packages("textstem", dependencies = TRUE)
#https://cran.r-project.org/web/packages/textclean/index.html
#install.packages("textclean", dependencies = TRUE)
#Loading the packages to the current workspace
lstPackages <- c('tm', 'RWeka', 'textstem', 'textclean')
lapply(lstPackages, library, character.only = TRUE)
```

## Read The Sample Data
```{r}
# Read The Sample Dataset
rawData <- read.csv(file = 'C:/Users/Kundana/Downloads/buffetpalace.csv', header = T, sep = ",")
numberofDocs <- length(rawData$stars)
rawData$id <- paste0("Doc", c(1:numberofDocs))
```

## Prepare The Corpora
```{r}
# Prepare The Corporate data 

listofDocs <- tm::VectorSource(rawData$text)
listofDocs$Names <- names(rawData$id)
corporaData <- tm::VCorpus(listofDocs)

```

## Cleaning and Preprocessing the text (Cleansing)
```{r}
#Lower casing the text
for(i in 1:383)
{
corporaData[[i]]$content <- tolower(corporaData[[i]]$content)
}

#Replacing number with words 

for(i in 1:383)
{
  corporaData[[i]]$content <- 
  as.character(textclean::replace_number(corporaData[[i]]$content))
}

#Utilizing a Thesaurus
for(i in 1:383)
{
    corporaData[[i]]$content <- 
    textstem::lemmatize_strings(corporaData[[i]]$content, 
                                dictionary = lexicon::hash_lemmas)
}

#Stemming
corporaData <- tm::tm_map(corporaData, stemDocument)

#Stopword Removal
corporaData <- tm::tm_map(corporaData, removeWords, stopwords('english')) 
corporaData <- tm::tm_map(corporaData, removeWords, stopwords('SMART')) 

#Other Pre-processing Steps: Punctuation Marks, Extra Whitespaces, etc 
corporaData <- tm::tm_map(corporaData, content_transformer(tolower))
corporaData <- tm::tm_map(corporaData, removePunctuation,  
                      ucp = TRUE, 
                      preserve_intra_word_contractions = FALSE,
                      preserve_intra_word_dashes = FALSE)

#corporaData <- tm::tm_map(corporaData, removeNumbers)
corporaData <- tm::tm_map(corporaData, stripWhitespace)

corporaData[[12]]$content


#(corporaData,"C:\\Users\\Kundana\\Downloads\\cleaneddata.csv", row.names = FALSE)

```

##Create a uni-gram Term Document Matrix
```{r}
# Create a uni-gram Term Document Matrix
term.doc.matrix.1g <- tm::TermDocumentMatrix(corporaData)
tm::inspect(term.doc.matrix.1g[1:10,])

# Represent TDM in a matrix format and display its dimensions
term.doc.matrix.unigram <- as.matrix(term.doc.matrix.1g)
dim(term.doc.matrix.unigram)
head(term.doc.matrix.unigram)
```


##Create a bi-gram Term Document Matrix
```{r}
# Create a bi-gram Term Document Matrix
tokenizer <- function(x) RWeka::NGramTokenizer(x, RWeka::Weka_control(min = 2, max = 2))
term.doc.matrix.2g <- tm::TermDocumentMatrix(corporaData, control = list(tokenize = tokenizer))
tm::inspect(term.doc.matrix.2g[1:10,])

# Represent TDM in a matrix format and display its dimensions
term.doc.matrix.bigram <- as.matrix(term.doc.matrix.2g)
dim(term.doc.matrix.bigram)
head(term.doc.matrix.bigram)
```


##reduce the dimension of the matrix
```{r}
term.doc.matrix.1g <- tm::removeSparseTerms(term.doc.matrix.1g, 0.8)
tm::inspect(term.doc.matrix.1g[1:10,])

term.doc.matrix.unigram <- as.matrix(term.doc.matrix.1g)
dim(term.doc.matrix.unigram)
head(term.doc.matrix.unigram)
```


##reduce the dimension of the matrix
```{r}
term.doc.matrix.2g <- tm::removeSparseTerms(term.doc.matrix.2g, 0.8)
tm::inspect(term.doc.matrix.2g[1:10,])

term.doc.matrix.bigram <- as.matrix(term.doc.matrix.2g)
dim(term.doc.matrix.bigram)
head(term.doc.matrix.bigram)
```

## Declaring weights (TF-IDF variants)
```{r}
# Declaring weights (TF-IDF variants)
tf.idf.weights <- function(tf.vec) {
  # Computes tfidf weights from term frequency vector
  n.docs <- length(tf.vec)
  doc.frequency <- length(tf.vec[tf.vec > 0])
  weights <- rep(0, length(tf.vec))
  relative.frequency <- tf.vec[tf.vec > 0] / sum(tf.vec[tf.vec > 0])
  weights[tf.vec > 0] <-  relative.frequency * log10(n.docs/doc.frequency)
  return(weights)
}
```


###Compute the TF-IDF (unigram)
```{r}
#Compute the TF-IDF (unigram)
tfidf.matrix.uni <- t(apply(as.matrix(term.doc.matrix.unigram), 1,
                        FUN = function(row) {tf.idf.weights(row)}))

colnames(tfidf.matrix.uni) <- rawData$id
head(tfidf.matrix.uni)
dim(tfidf.matrix.uni)
```

###Compute the TF-IDF (bigram)
```{r}
#Compute the TF-IDF (bigram)
tfidf.matrix.bi <- t(apply(as.matrix(term.doc.matrix.bigram), 1,
                        FUN = function(row) {tf.idf.weights(row)}))

colnames(tfidf.matrix.bi) <- rawData$id
head(tfidf.matrix.bi)
dim(tfidf.matrix.bi)
```


###Compute Cosine Similarity Indices
```{r}
#Compute Cosine Similarity indices for the uni-gram TDM 
c.similarity.matrix.uni <- text2vec::sim2(t(tfidf.matrix.uni), method = 'cosine')
#Compute Cosine Similarity Indices for the bi-gram TDM 
c.similarity.matrix.bi <- text2vec::sim2(t(tfidf.matrix.bi), method = 'cosine')
##Display Results
sort(round(c.similarity.matrix.uni["Doc24", ], 2), decreasing = TRUE)[1:383]
sort(round(c.similarity.matrix.bi["Doc24", ], 2), decreasing = TRUE)[1:383]
```

```{r}
library("gplots")
heatmap.2(c.similarity.matrix.uni, main = "Uni gram", scale = "none", col = greenred(50), 
          trace = "none", density.info = "none")


heatmap.2(c.similarity.matrix.bi, main = "Bi gram", scale = "none", col = greenred(50), 
          trace = "none", density.info = "none")
```

